Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cluster nodes: 50
Job counts:
	count	jobs
	1	SubAsterisk
	1	all
	2
Select jobs to execute...

[Mon May 24 18:41:34 2021]
rule SubAsterisk:
    input: resources/remerged_datasets/KB100/KB100_Chr01.vcf.gz
    output: results/SubAsterisk_KB100_Chr01.vcf.gz
    log: reports/SubAsterisk_KB100_Chr01.log
    jobid: 1
    wildcards: sample=KB100, chr=Chr01

Submitted job 1 with external jobid 'Submitted batch job 22843709'.
[Mon May 24 18:45:05 2021]
Finished job 1.
1 of 2 steps (50%) done
Select jobs to execute...

[Mon May 24 18:45:05 2021]
localrule all:
    input: results/SubAsterisk_KB100_Chr01.vcf.gz
    jobid: 0

[Mon May 24 18:45:05 2021]
Finished job 0.
2 of 2 steps (100%) done
Complete log: /storage/hpc/group/bilyeu/nad7wf/allele_atlas_pipeline/.snakemake/log/2021-05-24T184134.828619.snakemake.log
